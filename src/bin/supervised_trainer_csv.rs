//! CSV-based Supervised Trainer for GNN
//!
//! Trains neural networks on pure MCTS expert data generated by generate_supervised_dataset
//! Reads CSV format: game_id,turn,plateau_0-18,tile_0-2,position,final_score

use clap::Parser;
use csv::ReaderBuilder;
use flexi_logger::Logger;
use rand::prelude::*;
use rand::seq::SliceRandom;
use std::error::Error;
use std::fs::File;
use tch::{Device, Tensor};

use take_it_easy::data::augmentation::{augment_example, AugmentTransform};
use take_it_easy::neural::manager::NNArchitecture;
use take_it_easy::neural::{NeuralConfig, NeuralManager};

#[derive(Parser, Debug)]
#[command(
    name = "supervised-trainer-csv",
    about = "Train neural networks from CSV expert data"
)]
struct Args {
    /// CSV file with expert data
    #[arg(short, long)]
    data: String,

    /// Number of training epochs
    #[arg(short, long, default_value_t = 50)]
    epochs: usize,

    /// Batch size for training
    #[arg(short, long, default_value_t = 64)]
    batch_size: usize,

    /// Learning rate for policy network
    #[arg(long, default_value_t = 0.001)]
    policy_lr: f64,

    /// Learning rate for value network
    #[arg(long, default_value_t = 0.0001)]
    value_lr: f64,

    /// Neural network architecture (CNN or GNN)
    #[arg(long, default_value = "GNN")]
    nn_architecture: String,

    /// Validation split (0.0-1.0)
    #[arg(long, default_value_t = 0.1)]
    validation_split: f64,

    /// Random seed for shuffling
    #[arg(long, default_value_t = 42)]
    seed: u64,

    /// Enable data augmentation on-the-fly (random transformation per batch)
    #[arg(long, default_value_t = false)]
    augmentation: bool,

    /// Early stopping patience (epochs without improvement)
    #[arg(long, default_value_t = 10)]
    patience: usize,

    /// Use Q-values for value training (requires qvalue dataset format)
    #[arg(long, default_value_t = false)]
    qvalue_mode: bool,
}

#[derive(Debug, Clone)]
struct TrainingExample {
    plateau_state: Vec<i32>,  // 19 encoded tiles
    tile: (i32, i32, i32),    // Current tile
    position: usize,          // Target position (policy label)
    final_score: i32,         // Final game score (value label)
    qvalues: Option<[f32; 19]>, // Q-values for each position (if qvalue_mode)
}

fn main() -> Result<(), Box<dyn Error>> {
    Logger::try_with_env_or_str("info")?
        .format(flexi_logger::colored_default_format)
        .start()?;

    let args = Args::parse();

    log::info!("üéì CSV Supervised Trainer");
    log::info!("Architecture: {}", args.nn_architecture);
    log::info!("Data file: {}", args.data);
    log::info!("Epochs: {}", args.epochs);
    log::info!("Batch size: {}", args.batch_size);
    log::info!("Policy LR: {}", args.policy_lr);
    log::info!("Value LR: {}", args.value_lr);

    // Parse architecture
    let nn_arch = match args.nn_architecture.to_uppercase().as_str() {
        "CNN" => NNArchitecture::Cnn,
        "GNN" => NNArchitecture::Gnn,
        "CNN-ONEHOT" | "ONEHOT" => NNArchitecture::CnnOnehot,
        _ => return Err(format!("Invalid architecture: {}. Valid: CNN, GNN, CNN-ONEHOT", args.nn_architecture).into()),
    };

    // Load training data from CSV
    log::info!("\nüìÇ Loading training data from CSV...");
    if args.qvalue_mode {
        log::info!("üéØ Q-VALUE MODE: Using Q-values as value targets");
    }
    let examples = load_csv_data(&args.data, args.qvalue_mode)?;
    log::info!("‚úÖ Loaded {} training examples", examples.len());
    if args.qvalue_mode {
        let with_qv = examples.iter().filter(|e| e.qvalues.is_some()).count();
        log::info!("   {} examples have Q-values", with_qv);
    }

    if args.augmentation {
        log::info!("üîÑ Data augmentation: ON-THE-FLY (random transformation per batch)");
        log::info!("   Effective dataset size: {}x (no materialization)", examples.len());
    }

    log::info!("üìä Total training examples: {}", examples.len());

    // Calculate statistics
    let scores: Vec<i32> = examples.iter().map(|e| e.final_score).collect();
    let avg_score = scores.iter().sum::<i32>() as f64 / scores.len() as f64;
    let min_score = *scores.iter().min().unwrap();
    let max_score = *scores.iter().max().unwrap();
    log::info!("üìä Score statistics: avg={:.1}, range=[{}, {}]", avg_score, min_score, max_score);

    // Shuffle and split data
    let mut rng = rand::rngs::StdRng::seed_from_u64(args.seed);
    let mut shuffled = examples.clone();
    shuffled.shuffle(&mut rng);

    let split_idx = ((1.0 - args.validation_split) * shuffled.len() as f64) as usize;
    let (train_data, val_data) = shuffled.split_at(split_idx);
    log::info!("Split: {} training, {} validation examples", train_data.len(), val_data.len());

    // Initialize neural network
    log::info!("\nüß† Initializing {} neural network...", args.nn_architecture);

    // Get input channels based on architecture
    let input_dim = nn_arch.input_dim();
    log::info!("Input dimensions: {:?}", input_dim);

    let neural_config = NeuralConfig {
        input_dim,
        nn_architecture: nn_arch,
        policy_lr: args.policy_lr,
        value_lr: args.value_lr,
        ..Default::default()
    };
    let mut manager = NeuralManager::with_config(neural_config)?;
    log::info!("‚úÖ Neural network initialized");

    // Training loop
    log::info!("\nüèãÔ∏è Starting training...");
    let device = Device::Cpu;
    let mut best_val_loss = f64::INFINITY;
    let mut epochs_without_improvement = 0;

    for epoch in 0..args.epochs {
        // Training
        let (train_policy_loss, train_value_loss) = train_epoch(
            train_data,
            &mut manager,
            args.batch_size,
            device,
            args.augmentation,
            args.seed + epoch as u64,
            nn_arch,
        )?;

        // Validation
        let (val_policy_loss, val_value_loss) = validate_epoch(
            val_data,
            &manager,
            args.batch_size,
            device,
            nn_arch,
        )?;

        let total_val_loss = val_policy_loss + val_value_loss;

        // Log progress
        if (epoch + 1) % 5 == 0 || epoch == 0 || epoch == args.epochs - 1 {
            log::info!(
                "Epoch {:3}/{} | Train: policy={:.4}, value={:.4} | Val: policy={:.4}, value={:.4}",
                epoch + 1,
                args.epochs,
                train_policy_loss,
                train_value_loss,
                val_policy_loss,
                val_value_loss
            );
        }

        // Early stopping
        if total_val_loss < best_val_loss {
            best_val_loss = total_val_loss;
            epochs_without_improvement = 0;

            // Save best model
            manager.save_models()?;
            if (epoch + 1) % 10 == 0 {
                log::info!("üíæ Saved improved model (val_loss={:.4})", best_val_loss);
            }
        } else {
            epochs_without_improvement += 1;
            if epochs_without_improvement >= args.patience {
                log::info!(
                    "‚ö†Ô∏è Early stopping at epoch {} (no improvement for {} epochs)",
                    epoch + 1,
                    args.patience
                );
                break;
            }
        }
    }

    log::info!("\nüéâ Training Complete!");
    log::info!("Best validation loss: {:.4}", best_val_loss);
    log::info!("Model weights saved to default location");

    Ok(())
}

fn load_csv_data(path: &str, qvalue_mode: bool) -> Result<Vec<TrainingExample>, Box<dyn Error>> {
    let file = File::open(path)?;
    let mut reader = ReaderBuilder::new()
        .has_headers(true)
        .from_reader(file);

    let mut examples = Vec::new();

    for result in reader.records() {
        let record = result?;

        // Parse plateau state (columns 2-20: plateau_0 to plateau_18)
        let mut plateau_state = Vec::with_capacity(19);
        for i in 2..21 {
            let encoded: i32 = record[i].parse()?;
            plateau_state.push(encoded);
        }

        // Parse tile (columns 21-23: tile_0, tile_1, tile_2)
        let tile = (
            record[21].parse()?,
            record[22].parse()?,
            record[23].parse()?,
        );

        // Parse position and final_score
        // In qvalue_mode: col 24 is best_position, col 25 is final_score, cols 26-44 are qvalues
        // In normal mode: col 24 is position, col 25 is final_score
        let position: usize = record[24].parse()?;
        let final_score: i32 = record[25].parse()?;

        let qvalues = if qvalue_mode && record.len() > 26 {
            let mut qv = [0.0f32; 19];
            for i in 0..19 {
                qv[i] = record[26 + i].parse().unwrap_or(0.0);
            }
            Some(qv)
        } else {
            None
        };

        examples.push(TrainingExample {
            plateau_state,
            tile,
            position,
            final_score,
            qvalues,
        });
    }

    Ok(examples)
}

fn train_epoch(
    examples: &[TrainingExample],
    manager: &mut NeuralManager,
    batch_size: usize,
    device: Device,
    augment_on_fly: bool,
    seed: u64,
    arch: NNArchitecture,
) -> Result<(f64, f64), Box<dyn Error>> {
    let mut total_policy_loss = 0.0;
    let mut total_value_loss = 0.0;
    let mut num_batches = 0;

    let mut rng = rand::rngs::StdRng::seed_from_u64(seed);

    for batch in examples.chunks(batch_size) {
        // Apply on-the-fly augmentation if enabled
        let augmented_batch: Vec<TrainingExample> = if augment_on_fly {
            batch.iter().map(|example| {
                let transform = AugmentTransform::random(&mut rng);
                let (new_plateau, new_tile, new_position, score) = augment_example(
                    &example.plateau_state,
                    example.tile,
                    example.position,
                    example.final_score,
                    transform,
                );
                TrainingExample {
                    plateau_state: new_plateau,
                    tile: new_tile,
                    position: new_position,
                    final_score: score,
                    qvalues: None, // Q-values not preserved after augmentation
                }
            }).collect()
        } else {
            batch.to_vec()
        };

        let (state_tensors, policy_targets, value_targets) = prepare_batch_with_arch(&augmented_batch, device, arch)?;

        // Train policy network
        let policy_net = manager.policy_net();
        let policy_pred = policy_net.forward(&state_tensors, true);
        let policy_loss = policy_pred.cross_entropy_for_logits(&policy_targets);

        let policy_opt = manager.policy_optimizer_mut();
        policy_opt.backward_step(&policy_loss);
        total_policy_loss += f64::try_from(&policy_loss)?;

        // Train value network
        let value_net = manager.value_net();
        let value_pred = value_net.forward(&state_tensors, true);
        let value_loss = value_pred.mse_loss(&value_targets, tch::Reduction::Mean);

        let value_opt = manager.value_optimizer_mut();
        value_opt.backward_step(&value_loss);
        total_value_loss += f64::try_from(&value_loss)?;

        num_batches += 1;
    }

    Ok((
        total_policy_loss / num_batches as f64,
        total_value_loss / num_batches as f64,
    ))
}

fn validate_epoch(
    examples: &[TrainingExample],
    manager: &NeuralManager,
    batch_size: usize,
    device: Device,
    arch: NNArchitecture,
) -> Result<(f64, f64), Box<dyn Error>> {
    let mut total_policy_loss = 0.0;
    let mut total_value_loss = 0.0;
    let mut num_batches = 0;

    tch::no_grad(|| {
        for batch in examples.chunks(batch_size) {
            let (state_tensors, policy_targets, value_targets) = prepare_batch_with_arch(batch, device, arch)?;

            // Validate policy
            let policy_net = manager.policy_net();
            let policy_pred = policy_net.forward(&state_tensors, false);
            let policy_loss = policy_pred.cross_entropy_for_logits(&policy_targets);
            total_policy_loss += f64::try_from(&policy_loss)?;

            // Validate value
            let value_net = manager.value_net();
            let value_pred = value_net.forward(&state_tensors, false);
            let value_loss = value_pred.mse_loss(&value_targets, tch::Reduction::Mean);
            total_value_loss += f64::try_from(&value_loss)?;

            num_batches += 1;
        }
        Ok((
            total_policy_loss / num_batches as f64,
            total_value_loss / num_batches as f64,
        ))
    })
}

fn prepare_batch(
    examples: &[TrainingExample],
    device: Device,
) -> Result<(Tensor, Tensor, Tensor), Box<dyn Error>> {
    prepare_batch_with_arch(examples, device, NNArchitecture::Cnn)
}

fn prepare_batch_with_arch(
    examples: &[TrainingExample],
    device: Device,
    arch: NNArchitecture,
) -> Result<(Tensor, Tensor, Tensor), Box<dyn Error>> {
    let batch_size = examples.len();

    // GNN uses different tensor shape: [batch, 19, 8] instead of [batch, channels, 5, 5]
    if arch == NNArchitecture::Gnn {
        return prepare_batch_gnn(examples, device);
    }

    let (input_channels, encode_fn): (i64, fn(&[i32], &(i32, i32, i32)) -> Vec<f32>) = match arch {
        NNArchitecture::Cnn => (47, encode_state),
        NNArchitecture::CnnOnehot => (37, encode_state_onehot),
        NNArchitecture::Gnn => unreachable!(), // Handled above
    };

    let state_size = (input_channels as usize) * 5 * 5;

    // Prepare tensors
    let mut states = vec![0.0f32; batch_size * state_size];
    let mut policy_targets = vec![0i64; batch_size];
    let mut value_targets = vec![0.0f32; batch_size];

    for (i, example) in examples.iter().enumerate() {
        // Encode state using the appropriate encoding function
        let state = encode_fn(&example.plateau_state, &example.tile);
        let offset = i * state_size;
        states[offset..offset + state_size].copy_from_slice(&state);

        // Policy target: position
        policy_targets[i] = example.position as i64;

        // Value target: use Q-value if available, otherwise normalized final_score
        if let Some(qv) = &example.qvalues {
            // Use the Q-value of the chosen position as target
            // Q-values are already normalized to [0, 1]
            let qval = qv[example.position];
            value_targets[i] = if qval >= 0.0 { qval } else { 0.0 };
        } else {
            // Fallback: normalize final_score to [0, 1] range
            value_targets[i] = (example.final_score as f32) / 180.0;
        }
    }

    // CNN expects [batch, channels, height, width] = [batch, channels, 5, 5]
    let state_tensor = Tensor::from_slice(&states)
        .view([batch_size as i64, input_channels, 5, 5])
        .to_device(device);

    let policy_tensor = Tensor::from_slice(&policy_targets).to_device(device);

    let value_tensor = Tensor::from_slice(&value_targets)
        .view([batch_size as i64, 1])
        .to_device(device);

    Ok((state_tensor, policy_tensor, value_tensor))
}

/// Prepare batch specifically for GNN architecture
/// GNN uses shape [batch, 19, 8] instead of [batch, channels, 5, 5]
fn prepare_batch_gnn(
    examples: &[TrainingExample],
    device: Device,
) -> Result<(Tensor, Tensor, Tensor), Box<dyn Error>> {
    let batch_size = examples.len();
    const NODE_COUNT: usize = 19;
    const FEATURES: usize = 8;
    let state_size = NODE_COUNT * FEATURES;

    let mut states = vec![0.0f32; batch_size * state_size];
    let mut policy_targets = vec![0i64; batch_size];
    let mut value_targets = vec![0.0f32; batch_size];

    for (i, example) in examples.iter().enumerate() {
        let state = encode_state_gnn(&example.plateau_state, &example.tile);
        let offset = i * state_size;
        states[offset..offset + state_size].copy_from_slice(&state);

        policy_targets[i] = example.position as i64;

        // Value target: use Q-value if available
        if let Some(qv) = &example.qvalues {
            let qval = qv[example.position];
            value_targets[i] = if qval >= 0.0 { qval } else { 0.0 };
        } else {
            value_targets[i] = (example.final_score as f32) / 180.0;
        }
    }

    // GNN expects [batch, nodes, features] = [batch, 19, 8]
    let state_tensor = Tensor::from_slice(&states)
        .view([batch_size as i64, NODE_COUNT as i64, FEATURES as i64])
        .to_device(device);

    let policy_tensor = Tensor::from_slice(&policy_targets).to_device(device);

    let value_tensor = Tensor::from_slice(&value_targets)
        .view([batch_size as i64, 1])
        .to_device(device);

    Ok((state_tensor, policy_tensor, value_tensor))
}

/// Hexagonal plateau layout - VERTICAL columns with 3-4-5-4-3 tiles:
///
///      Col0    Col1    Col2    Col3    Col4
///                       7
///        0      3      8       12      16
///        1      4      9       13      17
///        2      5     10       14      18
///               6     11       15
///
/// Maps hex position (0-18) to (row, col) in 5√ó5 grid
const HEX_TO_GRID_MAP: [(usize, usize); 19] = [
    // Column 0 (positions 0-2): 3 tiles, rows 1-3
    (1, 0), (2, 0), (3, 0),
    // Column 1 (positions 3-6): 4 tiles, rows 1-4
    (1, 1), (2, 1), (3, 1), (4, 1),
    // Column 2 (positions 7-11): 5 tiles, rows 0-4
    (0, 2), (1, 2), (2, 2), (3, 2), (4, 2),
    // Column 3 (positions 12-15): 4 tiles, rows 1-4
    (1, 3), (2, 3), (3, 3), (4, 3),
    // Column 4 (positions 16-18): 3 tiles, rows 1-3
    (1, 4), (2, 4), (3, 4),
];

/// Convert hex position to grid index
#[inline]
fn hex_to_grid_idx(hex_pos: usize) -> usize {
    let (row, col) = HEX_TO_GRID_MAP[hex_pos];
    row * 5 + col
}

/// Line definitions for explicit line features
const LINE_DEFS: &[(&[usize], usize)] = &[
    (&[0, 1, 2], 0),           // Dir1 lines (tile.0)
    (&[3, 4, 5, 6], 0),
    (&[7, 8, 9, 10, 11], 0),
    (&[12, 13, 14, 15], 0),
    (&[16, 17, 18], 0),
    (&[0, 3, 7], 1),           // Dir2 lines (tile.1)
    (&[1, 4, 8, 12], 1),
    (&[2, 5, 9, 13, 16], 1),
    (&[6, 10, 14, 17], 1),
    (&[11, 15, 18], 1),
    (&[7, 12, 16], 2),         // Dir3 lines (tile.2)
    (&[3, 8, 13, 17], 2),
    (&[0, 4, 9, 14, 18], 2),
    (&[1, 5, 10, 15], 2),
    (&[2, 6, 11], 2),
];

fn encode_state(plateau: &[i32], tile: &(i32, i32, i32)) -> Vec<f32> {
    // STOCHZERO V2: 47 channels = 17 base + 30 line features
    // Base (17): tile values (3) + empty mask (1) + current tile (3) + turn (1) + bag (9)
    // Line features (30): 15 lines √ó 2 features (potential + tile compatibility)
    let mut state = vec![0.0f32; 47 * 5 * 5];

    let num_placed = plateau.iter().filter(|&&x| x != 0).count();
    let turn_progress = num_placed as f32 / 19.0;

    // Base encoding (channels 0-7) using CORRECT hexagonal mapping
    for (hex_pos, &encoded) in plateau.iter().enumerate() {
        // Use proper hex-to-grid mapping to preserve spatial structure
        let grid_idx = hex_to_grid_idx(hex_pos);

        if encoded == 0 {
            // Empty cell
            state[3 * 25 + grid_idx] = 1.0;
        } else {
            // Decode: encoded = v1*100 + v2*10 + v3
            let v1 = (encoded / 100) as f32 / 9.0;
            let v2 = ((encoded % 100) / 10) as f32 / 9.0;
            let v3 = (encoded % 10) as f32 / 9.0;

            state[grid_idx] = v1;
            state[25 + grid_idx] = v2;
            state[2 * 25 + grid_idx] = v3;
        }

        // Current tile (broadcast to all positions)
        state[4 * 25 + grid_idx] = tile.0 as f32 / 9.0;
        state[5 * 25 + grid_idx] = tile.1 as f32 / 9.0;
        state[6 * 25 + grid_idx] = tile.2 as f32 / 9.0;

        // Turn progress
        state[7 * 25 + grid_idx] = turn_progress;
    }

    // STOCHZERO: Reconstruct remaining deck (channels 8-16)
    // Create full deck and remove placed tiles + current tile
    use take_it_easy::game::create_deck::create_deck;
    use take_it_easy::game::tile::Tile;

    let mut remaining_deck = create_deck();

    // Remove placed tiles from deck
    for &encoded in plateau.iter() {
        if encoded != 0 {
            let v1 = encoded / 100;
            let v2 = (encoded % 100) / 10;
            let v3 = encoded % 10;
            let placed_tile = Tile(v1, v2, v3);

            if let Some(idx) = remaining_deck.tiles().iter().position(|t| *t == placed_tile) {
                remaining_deck.tiles_mut().remove(idx);
            }
        }
    }

    // Remove current tile from deck
    let current_tile = Tile(tile.0, tile.1, tile.2);
    if let Some(idx) = remaining_deck.tiles().iter().position(|t| *t == current_tile) {
        remaining_deck.tiles_mut().remove(idx);
    }

    // Compute bag value counts
    let mut counts_dir1 = [0u32; 3];  // [1, 5, 9]
    let mut counts_dir2 = [0u32; 3];  // [2, 6, 7]
    let mut counts_dir3 = [0u32; 3];  // [3, 4, 8]

    for tile_in_deck in remaining_deck.tiles() {
        // Count direction 1 values
        match tile_in_deck.0 {
            1 => counts_dir1[0] += 1,
            5 => counts_dir1[1] += 1,
            9 => counts_dir1[2] += 1,
            _ => {}
        }

        // Count direction 2 values
        match tile_in_deck.1 {
            2 => counts_dir2[0] += 1,
            6 => counts_dir2[1] += 1,
            7 => counts_dir2[2] += 1,
            _ => {}
        }

        // Count direction 3 values
        match tile_in_deck.2 {
            3 => counts_dir3[0] += 1,
            4 => counts_dir3[1] += 1,
            8 => counts_dir3[2] += 1,
            _ => {}
        }
    }

    // Broadcast bag features to all 19 hexagonal cells (channels 8-16)
    for hex_pos in 0..19 {
        let grid_idx = hex_to_grid_idx(hex_pos);

        // Direction 1: [1, 5, 9] normalized /9
        state[8 * 25 + grid_idx] = counts_dir1[0] as f32 / 9.0;
        state[9 * 25 + grid_idx] = counts_dir1[1] as f32 / 9.0;
        state[10 * 25 + grid_idx] = counts_dir1[2] as f32 / 9.0;

        // Direction 2: [2, 6, 7] normalized /9
        state[11 * 25 + grid_idx] = counts_dir2[0] as f32 / 9.0;
        state[12 * 25 + grid_idx] = counts_dir2[1] as f32 / 9.0;
        state[13 * 25 + grid_idx] = counts_dir2[2] as f32 / 9.0;

        // Direction 3: [3, 4, 8] normalized /9
        state[14 * 25 + grid_idx] = counts_dir3[0] as f32 / 9.0;
        state[15 * 25 + grid_idx] = counts_dir3[1] as f32 / 9.0;
        state[16 * 25 + grid_idx] = counts_dir3[2] as f32 / 9.0;
    }

    // EXPLICIT LINE FEATURES (channels 17-46)
    // For each of 15 scoring lines, add 2 features:
    // - Line potential: how valuable is this line?
    // - Tile compatibility: does current tile match this line's direction?
    let tile_values = [tile.0, tile.1, tile.2];

    for (line_idx, (positions, direction)) in LINE_DEFS.iter().enumerate() {
        // Get the tile value for this direction
        let tile_value = tile_values[*direction];

        // Analyze the line
        let mut empty_count = 0;
        let mut value_counts: [u32; 10] = [0; 10];
        let line_len = positions.len();

        for &pos in *positions {
            let encoded = plateau[pos];
            if encoded == 0 {
                empty_count += 1;
            } else {
                let v = match direction {
                    0 => encoded / 100,           // Dir1: first digit
                    1 => (encoded % 100) / 10,    // Dir2: second digit
                    2 => encoded % 10,            // Dir3: third digit
                    _ => 0,
                };
                if v > 0 && (v as usize) < 10 {
                    value_counts[v as usize] += 1;
                }
            }
        }

        let filled_count = line_len - empty_count;

        // Find dominant value and check if line is blocked
        let (dominant_value, dominant_count) = value_counts
            .iter()
            .enumerate()
            .max_by_key(|(_, &c)| c)
            .map(|(v, &c)| (v as i32, c))
            .unwrap_or((0, 0));

        // Compute line potential
        let potential = if filled_count == 0 {
            0.5  // Empty line - neutral potential
        } else if dominant_count == filled_count as u32 {
            // All filled tiles have same value - line is alive
            let fill_ratio = filled_count as f32 / line_len as f32;
            let value_weight = dominant_value as f32 / 9.0;
            0.5 + 0.5 * fill_ratio * value_weight
        } else {
            0.0  // Line is blocked (conflicting values)
        };

        // Compute tile compatibility
        let compatibility = if filled_count == 0 {
            0.5  // Empty line - neutral
        } else if tile_value == dominant_value {
            1.0  // Tile matches line
        } else {
            0.0  // Tile conflicts
        };

        // Broadcast line features to all positions in that line
        let channel_potential = 17 + line_idx * 2;
        let channel_compat = 18 + line_idx * 2;

        for &pos in *positions {
            let grid_idx = hex_to_grid_idx(pos);
            state[channel_potential * 25 + grid_idx] = potential;
            state[channel_compat * 25 + grid_idx] = compatibility;
        }
    }

    state
}

/// One-hot oriented encoding for better pattern matching
/// 37 channels total:
/// Ch 0-2: Dir1 one-hot [1,5,9] for placed tiles
/// Ch 3-5: Dir2 one-hot [2,6,7] for placed tiles
/// Ch 6-8: Dir3 one-hot [3,4,8] for placed tiles
/// Ch 9: Occupied mask
/// Ch 10-12: Dir1 one-hot for current tile (broadcast)
/// Ch 13-15: Dir2 one-hot for current tile (broadcast)
/// Ch 16-18: Dir3 one-hot for current tile (broadcast)
/// Ch 19: Turn progress
/// Ch 20-28: Bag counts (3 per direction)
/// Ch 29-36: Line potential features (compressed)
fn encode_state_onehot(plateau: &[i32], tile: &(i32, i32, i32)) -> Vec<f32> {
    const CHANNELS: usize = 37;
    let mut state = vec![0.0f32; CHANNELS * 5 * 5];

    let num_placed = plateau.iter().filter(|&&x| x != 0).count();
    let turn_progress = num_placed as f32 / 19.0;

    // Direction value mappings
    const DIR1_VALUES: [i32; 3] = [1, 5, 9];
    const DIR2_VALUES: [i32; 3] = [2, 6, 7];
    const DIR3_VALUES: [i32; 3] = [3, 4, 8];

    fn value_to_onehot_idx(value: i32, dir_values: &[i32; 3]) -> Option<usize> {
        dir_values.iter().position(|&v| v == value)
    }

    // Encode placed tiles
    for (hex_pos, &encoded) in plateau.iter().enumerate() {
        let grid_idx = hex_to_grid_idx(hex_pos);

        if encoded != 0 {
            let v1 = encoded / 100;
            let v2 = (encoded % 100) / 10;
            let v3 = encoded % 10;

            // Dir1 one-hot (channels 0-2)
            if let Some(idx) = value_to_onehot_idx(v1, &DIR1_VALUES) {
                state[idx * 25 + grid_idx] = 1.0;
            }
            // Dir2 one-hot (channels 3-5)
            if let Some(idx) = value_to_onehot_idx(v2, &DIR2_VALUES) {
                state[(3 + idx) * 25 + grid_idx] = 1.0;
            }
            // Dir3 one-hot (channels 6-8)
            if let Some(idx) = value_to_onehot_idx(v3, &DIR3_VALUES) {
                state[(6 + idx) * 25 + grid_idx] = 1.0;
            }
            // Occupied mask (channel 9)
            state[9 * 25 + grid_idx] = 1.0;
        }
    }

    // Current tile one-hot (broadcast to all hex cells)
    let tile_dir1_idx = value_to_onehot_idx(tile.0, &DIR1_VALUES);
    let tile_dir2_idx = value_to_onehot_idx(tile.1, &DIR2_VALUES);
    let tile_dir3_idx = value_to_onehot_idx(tile.2, &DIR3_VALUES);

    for hex_pos in 0..19 {
        let grid_idx = hex_to_grid_idx(hex_pos);

        // Dir1 one-hot (channels 10-12)
        if let Some(idx) = tile_dir1_idx {
            state[(10 + idx) * 25 + grid_idx] = 1.0;
        }
        // Dir2 one-hot (channels 13-15)
        if let Some(idx) = tile_dir2_idx {
            state[(13 + idx) * 25 + grid_idx] = 1.0;
        }
        // Dir3 one-hot (channels 16-18)
        if let Some(idx) = tile_dir3_idx {
            state[(16 + idx) * 25 + grid_idx] = 1.0;
        }
        // Turn progress (channel 19)
        state[19 * 25 + grid_idx] = turn_progress;
    }

    // Bag awareness (channels 20-28) - simplified counts
    use take_it_easy::game::create_deck::create_deck;
    use take_it_easy::game::tile::Tile;

    let mut remaining_deck = create_deck();

    // Remove placed tiles
    for &encoded in plateau.iter() {
        if encoded != 0 {
            let v1 = encoded / 100;
            let v2 = (encoded % 100) / 10;
            let v3 = encoded % 10;
            let placed_tile = Tile(v1, v2, v3);
            if let Some(idx) = remaining_deck.tiles().iter().position(|t| *t == placed_tile) {
                remaining_deck.tiles_mut().remove(idx);
            }
        }
    }

    // Remove current tile
    let current_tile = Tile(tile.0, tile.1, tile.2);
    if let Some(idx) = remaining_deck.tiles().iter().position(|t| *t == current_tile) {
        remaining_deck.tiles_mut().remove(idx);
    }

    // Compute bag counts
    let mut counts_dir1 = [0u32; 3];
    let mut counts_dir2 = [0u32; 3];
    let mut counts_dir3 = [0u32; 3];

    for t in remaining_deck.tiles() {
        if let Some(idx) = value_to_onehot_idx(t.0, &DIR1_VALUES) { counts_dir1[idx] += 1; }
        if let Some(idx) = value_to_onehot_idx(t.1, &DIR2_VALUES) { counts_dir2[idx] += 1; }
        if let Some(idx) = value_to_onehot_idx(t.2, &DIR3_VALUES) { counts_dir3[idx] += 1; }
    }

    // Broadcast bag counts (channels 20-28)
    for hex_pos in 0..19 {
        let grid_idx = hex_to_grid_idx(hex_pos);
        for i in 0..3 {
            state[(20 + i) * 25 + grid_idx] = counts_dir1[i] as f32 / 9.0;
            state[(23 + i) * 25 + grid_idx] = counts_dir2[i] as f32 / 9.0;
            state[(26 + i) * 25 + grid_idx] = counts_dir3[i] as f32 / 9.0;
        }
    }

    // Line potential features (channels 29-36) - simplified
    for (line_idx, &(positions, direction)) in LINE_DEFS.iter().enumerate() {
        let tile_value = match direction {
            0 => tile.0,
            1 => tile.1,
            2 => tile.2,
            _ => 0,
        };

        let mut empty_count = 0;
        let mut value_in_line: Option<i32> = None;
        let mut is_blocked = false;

        for &pos in positions {
            let encoded = plateau[pos];
            if encoded == 0 {
                empty_count += 1;
            } else {
                let v = match direction {
                    0 => encoded / 100,
                    1 => (encoded % 100) / 10,
                    2 => encoded % 10,
                    _ => 0,
                };
                match value_in_line {
                    None => value_in_line = Some(v),
                    Some(existing) if existing != v => is_blocked = true,
                    _ => {}
                }
            }
        }

        let filled_count = positions.len() - empty_count;

        let potential = if is_blocked {
            0.0
        } else if filled_count == 0 {
            0.5
        } else {
            let line_value = value_in_line.unwrap_or(0);
            let fill_ratio = filled_count as f32 / positions.len() as f32;
            let match_bonus = if tile_value == line_value { 0.3 } else { 0.0 };
            (0.3 + 0.4 * fill_ratio + match_bonus).min(1.0)
        };

        // Compress 15 lines into 8 channels
        let channel = 29 + (line_idx % 8);
        for &pos in positions {
            let grid_idx = hex_to_grid_idx(pos);
            let current = state[channel * 25 + grid_idx];
            state[channel * 25 + grid_idx] = current.max(potential);
        }
    }

    state
}

/// Encode state for GNN: 19 nodes √ó 8 features
/// Features per node:
///   [0]: tile.0 / 10 (direction 1 value, normalized)
///   [1]: tile.1 / 10 (direction 2 value, normalized)
///   [2]: tile.2 / 10 (direction 3 value, normalized)
///   [3]: empty mask (0 if empty, 1 if filled)
///   [4]: orientation_score direction 1
///   [5]: orientation_score direction 2
///   [6]: orientation_score direction 3
///   [7]: turn progress (normalized)
fn encode_state_gnn(plateau: &[i32], _tile: &(i32, i32, i32)) -> Vec<f32> {
    const NODE_COUNT: usize = 19;
    const FEATURES: usize = 8;
    let mut features = vec![0.0f32; NODE_COUNT * FEATURES];

    let num_placed = plateau.iter().filter(|&&x| x != 0).count();
    let turn_progress = num_placed as f32 / 19.0;

    // Compute orientation scores for each direction
    let orientation_scores = compute_orientation_scores_from_encoded(plateau);

    for node in 0..NODE_COUNT {
        let base = node * FEATURES;
        let encoded = plateau[node];

        if encoded == 0 {
            // Empty cell
            features[base] = 0.0;
            features[base + 1] = 0.0;
            features[base + 2] = 0.0;
            features[base + 3] = 0.0; // Empty
        } else {
            // Decode: encoded = v1*100 + v2*10 + v3
            let v1 = encoded / 100;
            let v2 = (encoded % 100) / 10;
            let v3 = encoded % 10;

            features[base] = (v1 as f32 / 10.0).clamp(0.0, 1.0);
            features[base + 1] = (v2 as f32 / 10.0).clamp(0.0, 1.0);
            features[base + 2] = (v3 as f32 / 10.0).clamp(0.0, 1.0);
            features[base + 3] = 1.0; // Filled
        }

        // Orientation scores
        features[base + 4] = orientation_scores[0][node];
        features[base + 5] = orientation_scores[1][node];
        features[base + 6] = orientation_scores[2][node];

        // Turn progress
        features[base + 7] = turn_progress;
    }

    features
}

/// Compute orientation scores from encoded plateau (for GNN)
fn compute_orientation_scores_from_encoded(plateau: &[i32]) -> [[f32; 19]; 3] {
    let mut orientation_scores = [[0.0f32; 19]; 3];

    for &(positions, orientation) in LINE_DEFS.iter() {
        let len = positions.len() as f32;
        if len <= 0.0 {
            continue;
        }

        let mut counts = [0usize; 10];
        let mut filled = 0usize;

        for &pos in positions {
            let encoded = plateau[pos];
            if encoded == 0 {
                continue;
            }

            let value = match orientation {
                0 => encoded / 100,           // Direction 1
                1 => (encoded % 100) / 10,    // Direction 2
                2 => encoded % 10,            // Direction 3
                _ => 0,
            };

            if value > 0 && value <= 9 {
                counts[value as usize] += 1;
            }
            filled += 1;
        }

        // Find dominant value and compute line quality
        let max_count = *counts.iter().max().unwrap_or(&0);
        let is_blocked = filled > max_count && max_count > 0;

        let line_quality = if filled == 0 {
            0.5 // Neutral potential
        } else if is_blocked {
            0.0 // Blocked line
        } else {
            // Progress toward completion
            (filled as f32 / len).min(1.0)
        };

        // Assign score to all positions in the line
        for &pos in positions {
            if pos < 19 {
                orientation_scores[orientation][pos] =
                    orientation_scores[orientation][pos].max(line_quality);
            }
        }
    }

    orientation_scores
}

