# üîç Diagnostic: Pourquoi le Transformer n'apprend pas

## R√©sum√© ex√©cutif

Le Transformer entra√Æn√© sur 100 epochs n'a atteint que **14.55 points** (m√©diane 0) vs **133 points** pour la baseline MCTS.

Apr√®s analyse approfondie du code, **5 probl√®mes majeurs** ont √©t√© identifi√©s.

---

## ‚ùå Probl√®me 1: Repr√©sentation d'√©tat trop simpliste

### Constat
**Fichier**: `src/neural/transformer/game_state.rs:8-32`

```rust
fn to_tensor_features(&self) -> Vec<f32> {
    let mut features = Vec::with_capacity(64);
    // 19 tuiles √ó 3 valeurs = 57 features
    for tile in &self.plateau.tiles {
        features.extend_from_slice(&[
            tile.0 as f32 / 9.0,
            tile.1 as f32 / 9.0,
            tile.2 as f32 / 9.0,
        ]);
    }
    // Padding √† 64...
}
```

### Probl√®mes:
1. **Perte d'information spatiale**: Les tuiles sont apla ties en un vecteur, perdant la structure hexagonale
2. **Pas de features de lignes**: Aucune information sur les lignes compl√®tes ou potentielles
3. **Deck sous-repr√©sent√©**: Une seule feature pour le deck (taille normalis√©e)
4. **Pas de contexte de jeu**: Tour actuel, score partiel, tuiles restantes sp√©cifiques

### Impact:
Le Transformer ne voit qu'un vecteur plat de 64 nombres sans structure, rendant l'apprentissage de patterns spatiaux quasi-impossible.

---

## ‚ùå Probl√®me 2: Taille de dataset insuffisante

### Constat
- **608 exemples** d'entra√Ænement total
- Batch size: 16 ‚Üí seulement **38 batches par epoch**
- Variance importante dans les scores (0-18 points)

### Contexte:
- Les Transformers n√©cessitent typiquement **10k-100k+ exemples**
- AlphaZero utilise des millions d'exemples
- Notre jeu a **27! ‚âà 10^28** √©tats possibles

### Impact:
Le mod√®le ne voit pas assez de diversit√© pour g√©n√©raliser. Il surfit ou sous-fit constamment.

---

## ‚ùå Probl√®me 3: Architecture inadapt√©e

### Constat
**Fichier**: `src/neural/transformer/mod.rs:30-34`

```rust
const NUM_LAYERS: i64 = 2;
const EMBEDDING_DIM: i64 = 64;
const NUM_HEADS: i64 = 2;
const FF_DIM: i64 = 128;
```

### Probl√®mes:
1. **Trop petit pour apprendre**: 2 couches, 64 dim ‚Üí ~40k param√®tres
2. **Reshape arbitraire**: Input [1, 5, 47] ‚Üí reshape ‚Üí [seq=4, dim=16]
3. **Pooling global**: `mean_dim` perd l'information de position

### Comparaison:
- AlphaZero ResNet: ~1M param√®tres
- Notre policy/value CNN: ~100k param√®tres
- Notre Transformer: ~40k param√®tres ‚ùå

### Impact:
Le mod√®le n'a pas assez de capacit√© pour capturer les patterns complexes du jeu.

---

## ‚ùå Probl√®me 4: Loss function probl√©matique

### Constat
**Fichier**: `src/neural/transformer/training.rs:205-230`

```rust
// Cr√©er un target de boost binaire
let boost_target_batch = (&boosted_target_batch - &policy_target_batch)
    .abs()
    .gt(0.01) // Si diff√©rence > 1%, c'est une position boost√©e
    .to_kind(Kind::Float);

// Combiner les trois losses
let loss: Tensor = policy_loss + value_loss + boost_loss * 0.3;
```

### Probl√®mes:
1. **D√©tection de boost na√Øve**: Diff√©rence > 1% ne capture pas bien les vrais boosts (qui peuvent √™tre x1000)
2. **Poids arbitraires**: 1.0 + 1.0 + 0.3 sans justification
3. **Pas de pond√©ration par difficult√©**: Toutes les positions comptent pareil
4. **Label smoothing sur policy**: R√©duit le signal d'apprentissage

### Impact:
Le mod√®le re√ßoit des signaux d'apprentissage confus et contradictoires.

---

## ‚ùå Probl√®me 5: Boosts presque identiques

### Constat
**Donn√©es inspect√©es**:
```
game_data_policy_raw_transformer.pt:
  Min: 0.0000, Max: 0.0902, Mean: 0.0526

game_data_policy_boosted_transformer.pt:
  Min: 0.0000, Max: 0.0648, Mean: 0.0526
```

### Probl√®me:
Les politiques boost√©es sont **presque identiques** aux politiques raw !
- Max raw: 0.0902
- Max boosted: 0.0648 (plus petit ?!)

Cela sugg√®re que :
1. **Les boosts ne sont pas appliqu√©s** correctement lors de la sauvegarde
2. **Ou normalisation √©crase les boosts** (softmax apr√®s boost ?)
3. **Ou les boosts sont trop faibles** dans MCTS

### Impact:
Le Transformer apprend √† copier MCTS raw, pas √† apprendre les heuristiques de boost qui donnent +20-40 points.

---

## ‚úÖ Solutions recommand√©es (par priorit√©)

### ü•á Priorit√© 1: Am√©liorer la repr√©sentation d'√©tat

```rust
fn to_tensor_features(&self) -> Vec<f32> {
    let mut features = Vec::with_capacity(256);

    // 1. Tuiles du plateau (19 √ó 3 = 57)
    for tile in &self.plateau.tiles {
        features.push(tile.0 as f32 / 9.0);
        features.push(tile.1 as f32 / 9.0);
        features.push(tile.2 as f32 / 9.0);
    }

    // 2. Lignes compl√®tes actuelles (10 lignes √ó 3 couleurs = 30)
    for line in get_all_lines() {
        let (complete_1, complete_5, complete_9) = check_line_completion(&self.plateau, line);
        features.push(if complete_1 { 1.0 } else { 0.0 });
        features.push(if complete_5 { 1.0 } else { 0.0 });
        features.push(if complete_9 { 1.0 } else { 0.0 });
    }

    // 3. Lignes potentielles (10 lignes √ó 3 couleurs = 30)
    for line in get_all_lines() {
        let (potential_1, potential_5, potential_9) = check_line_potential(&self.plateau, line);
        features.push(potential_1);
        features.push(potential_5);
        features.push(potential_9);
    }

    // 4. Score partiel actuel (1)
    features.push(current_score() / 200.0);

    // 5. Tour actuel (1)
    features.push(turn / 19.0);

    // 6. Tuiles disponibles par couleur (9 features)
    for color in 1..=9 {
        let count = count_tiles_with_color(&self.deck, color);
        features.push(count as f32 / 27.0);
    }

    // Total: 57 + 30 + 30 + 1 + 1 + 9 = 128 features
    features
}
```

### ü•à Priorit√© 2: G√©n√©rer beaucoup plus de donn√©es

```bash
# G√©n√©rer 5000 parties
cargo run --release --bin take_it_easy -- --mode autotest --num-games 5000 --num-simulations 150
```

### ü•â Priorit√© 3: Augmenter la capacit√© du mod√®le

```rust
const NUM_LAYERS: i64 = 4;        // 2 ‚Üí 4
const EMBEDDING_DIM: i64 = 128;   // 64 ‚Üí 128
const NUM_HEADS: i64 = 4;         // 2 ‚Üí 4
const FF_DIM: i64 = 512;          // 128 ‚Üí 512
```

### 4Ô∏è‚É£ Priorit√© 4: V√©rifier les boosts dans MCTS

Inspecter `src/mcts/algorithm.rs` pour s'assurer que :
1. Les boosts sont correctement appliqu√©s avant softmax
2. Les valeurs sont sauvegard√©es **apr√®s** boost mais **avant** normalisation
3. L'intensit√© du boost refl√®te la magnitude (x1000 pour ligne 9)

### 5Ô∏è‚É£ Priorit√© 5: Am√©liorer la loss function

```rust
// Pond√©ration adaptative selon le tour
let turn_weight = 1.0 + (current_turn as f32 / 19.0) * 2.0;

// Loss de policy avec focus sur les boosts r√©els
let policy_loss = cross_entropy_with_weights(policy_logits, policy_target_batch, boost_weights);

// Loss de value avec normalisation adapt√©e
let value_loss = huber_loss(value_pred, value_target_batch);

// Boost loss avec d√©tection plus robuste (seuil √† 0.1 au lieu de 0.01)
let boost_target = (&boosted_target_batch - &policy_target_batch).abs().gt(0.1);
let boost_loss = focal_loss(boost_logits, boost_target, alpha=0.25, gamma=2.0);

// Combiner avec pond√©ration dynamique
let loss = policy_loss * turn_weight + value_loss + boost_loss * 0.5;
```

---

## üìä M√©triques actuelles vs Objectif

| M√©trique | Actuel | Objectif | √âcart |
|----------|--------|----------|-------|
| Score moyen Transformer | 14.55 | >140 | -89.6% |
| Score m√©dian | 0 | >130 | -100% |
| Exemples d'entra√Ænement | 608 | 5000+ | -87.8% |
| Param√®tres mod√®le | ~40k | ~200k | -80% |
| Features d'√©tat | 64 | 128+ | -50% |
| Loss finale | 165.5 | <50 | +231% |

---

## üéØ Plan d'action recommand√©

**Phase 1 (Imm√©diat)**:
1. ‚úÖ Diagnostic complet (fait)
2. ‚è≥ Am√©liorer `to_tensor_features()` avec 128 features structur√©es
3. ‚è≥ V√©rifier que les boosts MCTS sont correctement sauvegard√©s

**Phase 2 (Court terme - 1-2h)**:
4. G√©n√©rer 5000 parties suppl√©mentaires
5. Augmenter l'architecture (4 layers, 128 dim)
6. R√©-entra√Æner 200 epochs

**Phase 3 (Moyen terme - 1 jour)**:
7. Impl√©menter les am√©liorations de loss function
8. Ajouter data augmentation (rotations, sym√©tries)
9. Validation crois√©e avec hold-out set

**Phase 4 (Long terme - 1 semaine)**:
10. Self-play it√©ratif (AlphaZero style)
11. Curriculum learning (commencer par fins de partie)
12. Ensemble de mod√®les

---

## üìö R√©f√©rences

- AlphaZero: https://arxiv.org/abs/1712.01815
- Attention Is All You Need: https://arxiv.org/abs/1706.03762
- Focal Loss: https://arxiv.org/abs/1708.02002
- Deep RL avec sparse rewards: https://arxiv.org/abs/1707.06347

---

**Conclusion**: Le Transformer n'apprend pas principalement √† cause de :
1. Repr√©sentation d'√©tat trop pauvre (64 features plates)
2. Dataset trop petit (608 exemples)
3. Architecture sous-dimensionn√©e (~40k params)

**Action imm√©diate**: Am√©liorer `to_tensor_features()` pour inclure des features structur√©es (lignes, potentiels, contexte de jeu).
