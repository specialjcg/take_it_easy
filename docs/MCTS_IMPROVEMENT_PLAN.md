# Plan d'AmÃ©lioration MCTS - MÃ©thode Mikado

**Date**: 2025-12-25
**Objectif Principal**: AmÃ©liorer les performances MCTS de 50-100% via optimisations zero-copy + parallelism
**Baseline Actuelle**: 159.95 pts (aprÃ¨s +8.8% de micro-optimisations hyperparamÃ¨tres)

---

## 1. Ã‰tat des Lieux : Diagnostic Complet

### 1.1 Historique des Optimisations PrÃ©cÃ©dentes

```
Baseline:        147.00 pts
Phase 1 (2025-11-07): 158.05 pts (+7.5%) - Weight tuning
Quick Wins (2025-11-10): 159.95 pts (+1.2%) - Temperature annealing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:           +8.8% via hyperparamÃ¨tres
```

**Conclusion**: Rendements dÃ©croissants. Les optimisations de poids/tempÃ©rature ont atteint leur plafond.
**Prochain palier**: Optimisations structurelles (algorithmic + systems-level).

---

### 1.2 Bottlenecks Critiques IdentifiÃ©s

#### ğŸ”´ **CRITIQUE #1: Clone Explosion (36,750 allocations/call)**

**Localisation**: `src/mcts/algorithm.rs:223-469`

**Pattern problÃ©matique**:
```rust
for _ in 0..adaptive_sims {                    // ~150 iterations
    for &position in &subset_moves {            // ~7 moves
        let mut temp_plateau = plateau.clone();     // ğŸ”´ Clone #1 (Vec<Tile> Ã— 19)
        let mut temp_deck = deck.clone();           // ğŸ”´ Clone #1 (Vec<Tile> Ã— ~50)

        for _ in 0..rollout_count {             // ~7 rollouts
            let lookahead_plateau = temp_plateau.clone(); // ğŸ”´ Clone #2
            let lookahead_deck = temp_deck.clone();       // ğŸ”´ Clone #2

            for &pos2 in &second_moves {        // ~15 moves
                let mut plateau2 = lookahead_plateau.clone(); // ğŸ”´ Clone #3
                let mut deck2 = lookahead_deck.clone();       // ğŸ”´ Clone #3

                simulate_games_smart(plateau2.clone(), deck2.clone(), None); // ğŸ”´ Clone #4 & #5
            }
        }
    }
}
```

**Calcul**:
- Adaptive sims: 150
- Subset moves: 7
- Rollout count: 7
- Second moves: 15
- **Total clones**: 150 Ã— 7 Ã— 7 Ã— 15 Ã— 2 = **220,500 Vec operations** + clones internes
- **Estimation conservative**: ~36,750 allocations significatives par appel MCTS

**Impact mesurÃ©**: -30% CPU time en profiling

---

#### ğŸŸ¡ **CRITIQUE #2: RAVE DÃ©sactivÃ©**

**Localisation**: `src/mcts/algorithm.rs:316-317`

```rust
// RAVE disabled - incompatible with Pattern Rollouts heuristics
// Pattern Rollouts biases introduce false correlations in RAVE statistics
```

**Analyse**:
- **Erreur conceptuelle**: RAVE et Pattern Rollouts sont compatibles avec blending adaptatif
- **Formule RAVE-UCT**: `Q(s,a) = Î² Ã— Q_RAVE(a) + (1-Î²) Ã— Q_MCTS(s,a)`
- **Î² adaptatif**: `Î² = sqrt(k / (3*N + k))` oÃ¹ k=300-500 selon littÃ©rature
- **BÃ©nÃ©fice attendu**: RÃ©duction variance 30-50%, convergence 2Ã— plus rapide early game

**RÃ©fÃ©rence**: Gelly & Silver (2011) - "Monte-Carlo tree search and rapid action value estimation in computer Go"

---

#### ğŸŸ¡ **CRITIQUE #3: Progressive Widening Non UtilisÃ©**

**Localisation**: `src/mcts/progressive_widening.rs` (330 lignes de dead code)

**Ã‰tat**:
- âœ… ImplÃ©mentation complÃ¨te avec configs adaptive/conservative/aggressive
- âœ… Formule `k(n) = C Ã— n^Î±` correctement implÃ©mentÃ©e
- âŒ **Jamais appelÃ© dans algorithm.rs**
- âŒ Branching factor reste fixÃ© Ã  19 positions au lieu de 5-7 dynamiques

**BÃ©nÃ©fice attendu**:
- RÃ©duction simulations inutiles: 40-60%
- Focus computational sur top moves avec confidence

---

#### ğŸŸ  **CRITIQUE #4: Zero ParallÃ©lisme**

**Constat**:
- `rayon = "1.10.0"` dans Cargo.toml
- **0 usage** dans src/mcts/ (grep confirmÃ©)
- Machine typique: 8 cores
- Speedup potentiel: **6-8Ã— avec Virtual Loss**

**RÃ©fÃ©rence**: Chaslot et al. (2008) - "Parallel Monte-Carlo Tree Search"

---

## 2. MÃ©thode Mikado : Arbre de DÃ©pendances

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¯ OBJECTIF: MCTS 50-100% plus rapide (cargo test passing)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Branch  â”‚       â”‚   Branch    â”‚      â”‚  Leaf   â”‚
   â”‚ Clone   â”‚       â”‚  Parallel   â”‚      â”‚  PW     â”‚
   â”‚ Removal â”‚       â”‚   MCTS      â”‚      â”‚  Integ  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”             â”‚
   â”‚  Leaf   â”‚         â”‚  Leaf   â”‚             â”‚
   â”‚  RAVE   â”‚         â”‚ Virtual â”‚             â”‚
   â”‚  Impl   â”‚         â”‚  Loss   â”‚             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                               â”‚
                       LÃ©gende:                â”‚
                       ğŸƒ Leaf = Safe start    â”‚
                       ğŸŒ¿ Branch = Depends     â”‚
                                               â–¼
```

---

## 3. Plan d'ImplÃ©mentation : Feuilles â†’ Racine

### ğŸƒ **LEAF 1: Progressive Widening Integration** [SAFE - 2h]

**Objectif**: Activer le code existant dans l'algorithme principal

**Fichiers**:
- `src/mcts/algorithm.rs` (modification lÃ©gÃ¨re)
- `src/mcts/progressive_widening.rs` (dÃ©jÃ  existant)

**Changements**:
1. Import: `use crate::mcts::progressive_widening::*;`
2. Calculer `max_actions` avant loop:
   ```rust
   let pw_config = ProgressiveWideningConfig::adaptive(current_turn, 19);
   let max_actions_to_explore = calculate_max_actions(
       total_visits as usize,
       legal_moves.len(),
       &pw_config
   );
   ```
3. Limiter `subset_moves` Ã  `max_actions_to_explore` au lieu de `top_k`

**Tests**:
```bash
cargo test mcts::tests --release
cargo test game::tests::test_ai_vs_random --release -- --nocapture
```

**Rollback**: Simple `git revert` si rÃ©gression

**BÃ©nÃ©fice attendu**: -40% simulations redondantes, +15-25% performance

---

### ğŸƒ **LEAF 2: Virtual Loss Infrastructure** [SAFE - 3h]

**Objectif**: Ajouter structures pour parallÃ©lisme sans modifier l'algorithme principal

**Nouveau fichier**: `src/mcts/virtual_loss.rs`

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

/// Virtual Loss table for parallel MCTS
/// Tracks temporary losses applied during parallel simulations
pub struct VirtualLossTable {
    losses: Arc<Mutex<HashMap<(usize, usize), f64>>>,
    lambda: f64, // Virtual loss penalty (default: 1.0-3.0)
}

impl VirtualLossTable {
    pub fn new(lambda: f64) -> Self {
        Self {
            losses: Arc::new(Mutex::new(HashMap::new())),
            lambda,
        }
    }

    pub fn apply_virtual_loss(&self, state_hash: usize, action: usize) {
        let mut losses = self.losses.lock().unwrap();
        *losses.entry((state_hash, action)).or_insert(0.0) += self.lambda;
    }

    pub fn remove_virtual_loss(&self, state_hash: usize, action: usize) {
        let mut losses = self.losses.lock().unwrap();
        if let Some(loss) = losses.get_mut(&(state_hash, action)) {
            *loss -= self.lambda;
            if *loss <= 0.0 {
                losses.remove(&(state_hash, action));
            }
        }
    }

    pub fn get_virtual_loss(&self, state_hash: usize, action: usize) -> f64 {
        self.losses.lock().unwrap()
            .get(&(state_hash, action))
            .copied()
            .unwrap_or(0.0)
    }
}
```

**Tests unitaires**:
```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_virtual_loss_apply_remove() { /* ... */ }

    #[test]
    fn test_concurrent_access() { /* use rayon */ }
}
```

**Fichier modifiÃ©**: `src/mcts/mod.rs` (ajouter `pub mod virtual_loss;`)

**Tests**:
```bash
cargo test virtual_loss --release
cargo clippy -- -D warnings
```

**BÃ©nÃ©fice**: Infrastructure prÃªte pour parallÃ©lisation (pas de perf change encore)

---

### ğŸŒ¿ **BRANCH 3: Zero-Copy Plateau via Copy-on-Write** [COMPLEX - 6h]

**Objectif**: Ã‰liminer 36,750 clones avec Rc<RefCell<>> ou Arc<RwLock<>>

**DÃ©pendance**: NÃ©cessite LEAF 1 & 2 complÃ©tÃ©s (reduced surface area)

**StratÃ©gie**:
1. **Phase 3.1**: CrÃ©er wrapper CoW pour Plateau
   ```rust
   use std::rc::Rc;
   use std::cell::RefCell;

   #[derive(Clone)]
   pub struct PlateauCoW {
       data: Rc<RefCell<Plateau>>,
   }

   impl PlateauCoW {
       pub fn new(plateau: Plateau) -> Self {
           Self { data: Rc::new(RefCell::new(plateau)) }
       }

       pub fn clone_for_modification(&self) -> PlateauCoW {
           // Only clone when actually mutating
           let cloned = self.data.borrow().clone();
           PlateauCoW::new(cloned)
       }

       pub fn read<F, R>(&self, f: F) -> R
       where F: FnOnce(&Plateau) -> R
       {
           f(&self.data.borrow())
       }
   }
   ```

2. **Phase 3.2**: Remplacer progressivement dans algorithm.rs
   - Signature: `mcts_core_hybrid(plateau: PlateauCoW, ...)`
   - Modifier ligne 223: `let temp_plateau = plateau.clone_for_modification();`
   - Lectures: `plateau.read(|p| get_legal_moves(p))`

3. **Phase 3.3**: MÃªme pattern pour Deck

**Tests aprÃ¨s chaque phase**:
```bash
cargo test --release
cargo bench mcts_benchmark # VÃ©rifier perf gain
```

**Rollback**: Chaque phase committÃ©e sÃ©parÃ©ment

**BÃ©nÃ©fice attendu**: -30% CPU time, +40-60% throughput

---

### ğŸŒ¿ **BRANCH 4: RAVE Implementation** [MODERATE - 4h]

**DÃ©pendance**: BRANCH 3 (moins de clones = moins de friction pour tracking RAVE)

**Nouveau fichier**: `src/mcts/rave.rs`

```rust
use std::collections::HashMap;

pub struct RaveStatistics {
    action_values: HashMap<usize, f64>,
    action_visits: HashMap<usize, usize>,
}

impl RaveStatistics {
    pub fn new() -> Self {
        Self {
            action_values: HashMap::new(),
            action_visits: HashMap::new(),
        }
    }

    pub fn update(&mut self, action: usize, reward: f64) {
        let visits = self.action_visits.entry(action).or_insert(0);
        *visits += 1;

        let value = self.action_values.entry(action).or_insert(0.0);
        *value += (reward - *value) / (*visits as f64); // Incremental mean
    }

    pub fn get_value(&self, action: usize) -> f64 {
        self.action_values.get(&action).copied().unwrap_or(0.0)
    }

    pub fn get_visits(&self, action: usize) -> usize {
        self.action_visits.get(&action).copied().unwrap_or(0)
    }

    /// Calculate RAVE blending factor (Gelly & Silver formula)
    pub fn compute_beta(&self, total_visits: usize, k: f64) -> f64 {
        // Î² = sqrt(k / (3*N + k))
        (k / (3.0 * total_visits as f64 + k)).sqrt()
    }
}

pub fn blend_rave_uct(
    mcts_value: f64,
    rave_value: f64,
    beta: f64,
) -> f64 {
    beta * rave_value + (1.0 - beta) * mcts_value
}
```

**IntÃ©gration dans algorithm.rs**:
```rust
// AprÃ¨s ligne 312
let mut rave_stats = RaveStatistics::new();

// Dans la boucle de simulation (ligne 420+)
// Track toutes les actions visitÃ©es dans le rollout
let visited_actions = vec![position]; // + actions du simulate_games_smart
for &action in &visited_actions {
    rave_stats.update(action, simulated_score);
}

// Calcul UCB (ligne 462+)
let beta = rave_stats.compute_beta(total_visits as usize, 300.0);
let rave_value = rave_stats.get_value(position);
let blended_value = blend_rave_uct(average_score, rave_value, beta);
```

**Tests**:
```bash
cargo test rave --release
# VÃ©rifier que beta dÃ©croÃ®t avec visits (RAVE â†’ MCTS over time)
```

**BÃ©nÃ©fice attendu**: -30% variance early game, convergence 2Ã— plus rapide

---

### ğŸ¯ **ROOT 5: Parallel MCTS with Rayon** [COMPLEX - 8h]

**DÃ©pendance**: Tous LEAF & BRANCH complÃ©tÃ©s

**Objectif**: ParallÃ©liser les simulations avec rayon + Virtual Loss

**Modifications algorithm.rs**:
```rust
use rayon::prelude::*;
use crate::mcts::virtual_loss::VirtualLossTable;

pub fn mcts_core_hybrid_parallel(
    plateau: PlateauCoW,
    deck: DeckCoW,
    num_simulations: usize,
    num_threads: usize, // Nouveau param
    // ...
) -> usize {
    let vl_table = Arc::new(VirtualLossTable::new(2.0)); // lambda=2.0

    // ParallÃ©liser la boucle principale (ligne 387)
    (0..adaptive_simulations)
        .into_par_iter()
        .chunks(adaptive_simulations / num_threads)
        .for_each(|chunk| {
            for _ in chunk {
                let state_hash = compute_hash(&plateau); // Zobrist hashing

                // Select action with virtual loss
                let position = select_best_uct_with_virtual_loss(
                    &ucb_scores,
                    &vl_table,
                    state_hash
                );

                // Apply virtual loss before simulation
                vl_table.apply_virtual_loss(state_hash, position);

                // Simulate (thread-safe via CoW)
                let score = run_simulation(plateau.clone(), deck.clone(), position);

                // Update stats (needs Mutex/RwLock)
                update_statistics_threadsafe(position, score);

                // Remove virtual loss after completion
                vl_table.remove_virtual_loss(state_hash, position);
            }
        });
}
```

**Structures thread-safe**:
```rust
use std::sync::{Arc, RwLock};

struct ThreadSafeMCTSStats {
    visit_counts: Arc<RwLock<HashMap<usize, usize>>>,
    total_scores: Arc<RwLock<HashMap<usize, f64>>>,
}
```

**Tests**:
```bash
# Test sÃ©quentiel vs parallÃ¨le donnent mÃªmes rÃ©sultats (Â±variance)
cargo test test_parallel_determinism --release

# Benchmark speedup
cargo bench mcts_parallel_8threads
```

**BÃ©nÃ©fice attendu**: 6-8Ã— speedup sur machine 8-core

---

## 4. Estimation d'Impact Total

| Optimisation | Gain Attendu | ComplexitÃ© | Temps |
|--------------|--------------|------------|-------|
| ğŸƒ Progressive Widening | +15-25% | Faible | 2h |
| ğŸƒ Virtual Loss Infra | 0% (prep) | Faible | 3h |
| ğŸŒ¿ Zero-Copy (CoW) | +40-60% | Moyenne | 6h |
| ğŸŒ¿ RAVE Blending | +20-30% | Moyenne | 4h |
| ğŸ¯ Parallel MCTS | +600-800% (8 cores) | Haute | 8h |
| **TOTAL CUMULATIF** | **+150-300%** | - | **23h** |

**Gain conservateur attendu**: 159.95 pts â†’ **240-320 pts** (+50-100%)

---

## 5. Ordre d'ExÃ©cution RecommandÃ©

### Sprint 1: Quick Wins (5h)
1. âœ… LEAF 1: Progressive Widening (+15-25%, 2h)
2. âœ… LEAF 2: Virtual Loss Infra (0%, 3h)
3. âœ… Commit: "feat(mcts): integrate progressive widening and virtual loss infrastructure"
4. âœ… Run full test suite: `cargo test --release`

### Sprint 2: Structural (10h)
5. âœ… BRANCH 3.1: PlateauCoW wrapper (2h)
6. âœ… BRANCH 3.2: Refactor algorithm.rs reads (2h)
7. âœ… BRANCH 3.3: DeckCoW + full integration (2h)
8. âœ… Commit: "refactor(mcts): eliminate clones with copy-on-write pattern"
9. âœ… BRANCH 4: RAVE implementation (4h)
10. âœ… Commit: "feat(mcts): implement RAVE with adaptive blending"
11. âœ… Benchmark: `cargo bench` (valider gains cumulÃ©s)

### Sprint 3: Parallelism (8h)
12. âœ… ROOT 5.1: Thread-safe stats structures (2h)
13. âœ… ROOT 5.2: Rayon integration (3h)
14. âœ… ROOT 5.3: Virtual Loss + Zobrist hashing (3h)
15. âœ… Commit: "feat(mcts): parallel MCTS with rayon and virtual loss"
16. âœ… Final benchmark: `cargo bench --all`
17. âœ… Integration test: `cargo test test_ai_strength --release -- --nocapture`

---

## 6. CritÃ¨res de SuccÃ¨s

### Tests de Non-RÃ©gression
- âœ… `cargo test` â†’ 207/207 tests passing
- âœ… `cargo clippy -- -D warnings` â†’ 0 warnings
- âœ… `cargo build --release` â†’ successful

### Benchmarks de Performance
- âœ… AprÃ¨s Progressive Widening: â‰¥175 pts (+10%)
- âœ… AprÃ¨s Zero-Copy: â‰¥210 pts (+20% additionnel)
- âœ… AprÃ¨s RAVE: â‰¥230 pts (+10% additionnel)
- âœ… AprÃ¨s Parallel: â‰¥280 pts (+20% additionnel)

### MÃ©triques Techniques
- âœ… Allocations/call: 36,750 â†’ <1,000 (-97%)
- âœ… CPU time/move: baseline â†’ -50% (2Ã— plus rapide)
- âœ… ScalabilitÃ©: Speedup linÃ©aire jusqu'Ã  8 cores (RÂ² > 0.95)

---

## 7. Risques et Mitigations

| Risque | ProbabilitÃ© | Impact | Mitigation |
|--------|-------------|--------|------------|
| CoW overhead > clone cost | Faible | Moyen | Benchmark aprÃ¨s chaque phase, rollback si rÃ©gression |
| RAVE false correlations | Moyen | Faible | Tuner Î² adaptativement, k=300-500 range |
| Race conditions (parallel) | Moyen | Haut | Tests dÃ©terministes, Mutex/RwLock, code review |
| Thread contention | Faible | Moyen | Profiler avec `perf`, ajuster grain parallelism |

---

## 8. RÃ©fÃ©rences AcadÃ©miques

1. **RAVE**: Gelly & Silver (2011) - "Monte-Carlo tree search and rapid action value estimation in computer Go"
2. **Progressive Widening**: Coulom (2007) - "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"
3. **Virtual Loss**: Chaslot et al. (2008) - "Parallel Monte-Carlo Tree Search"
4. **UCT Algorithm**: Kocsis & SzepesvÃ¡ri (2006) - "Bandit based Monte-Carlo Planning"

---

## 9. Next Steps

**DÃ©marrer immÃ©diatement par**:
```bash
# CrÃ©er branche feature
git checkout -b feat/mcts-performance-boost

# Sprint 1 - LEAF 1
# Modifier src/mcts/algorithm.rs pour intÃ©grer Progressive Widening
```

**Validation continue**:
- Commit aprÃ¨s chaque LEAF/BRANCH
- Run `cargo test --release` avant chaque commit
- Benchmark intermÃ©diaire aprÃ¨s chaque sprint

---

**PrÃªt Ã  commencer ?** ğŸš€
