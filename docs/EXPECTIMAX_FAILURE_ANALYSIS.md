# Analyse Post-Mortem: Pourquoi Expectimax MCTS √âchoue sur Take It Easy

*Analyse approfondie des limites pratiques des approches stochastiques en MCTS*

---

## üìã R√©sum√© Ex√©cutif

**R√©sultat empirique:** Expectimax MCTS obtient **1.33 pts** vs Baseline **139.40 pts** (-99.0%)

**Verdict:** √âchec catastrophique malgr√© une impl√©mentation techniquement correcte

**Causes identifi√©es:** 4 niveaux de probl√®mes, du bug d'impl√©mentation aux limites th√©oriques fondamentales

---

## üî¨ M√©thodologie de l'Analyse

### Configuration Test√©e
```yaml
Jeu: Take It Easy (placement de tuiles, grille 19 cases)
Impl√©mentation: Expectimax MCTS avec CNN value network
Baseline: MCTS + Pattern Rollouts V2 + CNN
Simulations: 150 par coup
Architecture: CNN (8 canaux, 64 features)
Games test√©es: 3 (seed 2025)
```

### Donn√©es Empiriques Collect√©es
- Structure de l'arbre de recherche (profondeur, largeur)
- Distribution des valeurs par position
- Temps de calcul par coup
- Patterns de s√©lection UCB
- Scores finaux obtenus

---

## üêõ Niveau 1: Bug d'Impl√©mentation (Progressive Widening D√©faillant)

### Sympt√¥me Observ√©

```
After 150 simulations:
  Root (Decision node): 150 visits, 1 child  ‚Üê ANOMALIE!
  Expected: 19 children (19 positions l√©gales)
  Actual: 1 child only
```

### Diagnostic

Le progressive widening est cass√© par la logique `is_leaf()`:

```rust
// src/mcts/node.rs:165
pub fn is_leaf(&self) -> bool {
    self.children.is_empty()  // ‚Üê Retourne false d√®s qu'il y a 1 enfant
}

// src/mcts/expectimax_algorithm.rs:195
if node.is_leaf() {
    match &node.node_type {
        NodeType::Decision { .. } => {
            node.expand_one_child();  // ‚Üê N'est JAMAIS appel√© apr√®s le 1er enfant
        }
    }
}
```

### Comportement R√©el

```
Simulation 1:
  Root (0 children) ‚Üí is_leaf()=true ‚Üí expand_one_child()
  ‚Üí Cr√©e Chance node pour position 0

Simulations 2-150:
  Root (1 child) ‚Üí is_leaf()=false ‚Üí select_best_child(0)
  ‚Üí Descend TOUJOURS dans position 0
  ‚Üí Ne cr√©e JAMAIS les positions 1-18
```

### Impact

- L'arbre ne grandit qu'EN PROFONDEUR, jamais en largeur
- Une seule branche est explor√©e (position 0)
- Les 18 autres positions ne sont jamais consid√©r√©es
- L'algorithme choisit position 0 par d√©faut ‚Üí score catastrophique

### Solution Th√©orique

Impl√©menter un vrai progressive widening:

```rust
// Expansion bas√©e sur le nombre de visites
if !node.is_fully_expanded() {
    let visits_threshold = (node.visit_count as f64).sqrt() as usize;
    if node.children.len() < visits_threshold.min(max_children) {
        node.expand_one_child();
    }
}
```

**MAIS:** M√™me avec cette correction, les 3 autres niveaux de probl√®mes subsistent...

---

## ‚ö†Ô∏è Niveau 2: Explosion Combinatoire (Dilution du Budget de Simulations)

### Mod√®le Th√©orique

Expectimax construit un arbre Chance/Decision altern√©:

```
Root (Decision: o√π placer tuile connue?)
‚îú‚îÄ Pos 0 (Chance: quelle tuile ensuite?)
‚îÇ  ‚îú‚îÄ Tile 1 (Decision: o√π la placer?)
‚îÇ  ‚îú‚îÄ Tile 2 (Decision: o√π la placer?)
‚îÇ  ‚îú‚îÄ ...
‚îÇ  ‚îî‚îÄ Tile 27
‚îú‚îÄ Pos 1 (Chance)
‚îÇ  ‚îî‚îÄ ... 27 tiles
‚îú‚îÄ ...
‚îî‚îÄ Pos 18 (Chance)
   ‚îî‚îÄ ... 27 tiles
```

### Calcul du Facteur de Branchement

**Premier niveau (Decision):** 19 positions l√©gales
**Deuxi√®me niveau (Chance):** 27 tuiles possibles par position
**Troisi√®me niveau (Decision):** ~18 positions l√©gales

**Total branches 2 niveaux:** 19 √ó 27 = **513 n≈ìuds**
**Total branches 3 niveaux:** 19 √ó 27 √ó 18 = **9,234 n≈ìuds**

### Distribution du Budget

Avec 150 simulations:

| Niveau | N≈ìuds | Visites/n≈ìud | Profondeur atteinte |
|--------|-------|--------------|---------------------|
| 1 (Decision) | 19 | 7.9 | ‚úì Explor√© |
| 2 (Chance) | 513 | 0.29 | ‚ö†Ô∏è Sous-√©chantillonn√© |
| 3 (Decision) | 9,234 | 0.016 | ‚ùå Quasi inexplor√© |
| 4+ | >100,000 | <0.001 | ‚ùå Jamais atteint |

### Cons√©quence: √âvaluations Peu Informatives

```python
# Chaque position √©valu√©e avec ~8 samples
# Pour un jeu o√π le score d√©pend de 19 coups successifs
# ‚Üí Variance √©norme, signal noy√© dans le bruit
```

**Comparaison avec Baseline MCTS:**

| M√©trique | Expectimax | Baseline |
|----------|-----------|----------|
| Facteur branchement niveau 1 | 513 | 19 |
| Profondeur moyenne atteinte | 1.5 | 4-5 |
| Visites par action candidate | 0.29 | 7-8 |
| Signal/bruit | Tr√®s faible | Fort |

### Citation des Recherches

> "Stochastic MCTS requires O(b¬≤) more simulations than deterministic MCTS, where b is the branching factor of chance nodes."
> ‚Äî Browne et al., "A Survey of Monte Carlo Tree Search Methods" (2012)

Pour Take It Easy: b=27 ‚Üí **729√ó plus de simulations n√©cessaires** qu'un MCTS classique!

---

## üé≤ Niveau 3: Mauvaise Mod√©lisation de l'Incertitude (Th√©orie vs Pratique)

### L'Hypoth√®se Th√©orique

**Expectimax suppose:** Mod√©liser l'incertitude des **futurs tirages** am√©liore la d√©cision **actuelle**.

**Justification th√©orique:**
```
Valeur d'une position = E[score futur | tuiles futures al√©atoires]
‚Üí En moyennant sur les tirages possibles, on estime la "vraie" valeur
‚Üí D√©cision plus robuste
```

### Ce Qui Se Passe en Pratique

#### Structure Temporelle du Jeu

```
Take It Easy - S√©quence r√©elle:
1. Tirage al√©atoire de tuile T (uniforme)
2. D√âCISION: o√π placer T? (d√©terministe apr√®s tirage)
3. R√©p√©ter 19 fois
4. Score final calcul√©

Point cl√©: L'incertitude est R√âSOLUE avant la d√©cision!
```

#### Ce Qu'Expectimax Mod√©lise (inutilement)

```
Expectimax - Mod√®le interne:
1. Choisis position P
2. Simule tous les tirages futurs possibles
3. Pour chaque tirage, √©value le score
4. Moyenne sur tous les sc√©narios

Probl√®me: On simule l'incertitude de coups FUTURS alors que:
- La d√©cision actuelle d√©pend UNIQUEMENT de la tuile actuelle
- Les futurs tirages sont ind√©pendants du placement actuel
```

### Analyse Informationelle

**Quantit√© d'information mutuelle:**

```
I(Position actuelle ; Futurs tirages) ‚âà 0  (ind√©pendance)
I(Position actuelle ; Score final | Tuile actuelle) >> 0  (forte d√©pendance)
```

**Traduction:** Expectimax utilise 99% de son budget computationnel √† mod√©liser une incertitude **non pertinente** pour la d√©cision actuelle.

### Comparaison: O√π Expectimax SERAIT Pertinent

**Exemple 1: Backgammon**
```
Structure du jeu:
1. Lance 2 d√©s (al√©atoire)
2. D√âCISION: bouger quels pions?
3. L'adversaire lance ses d√©s (al√©atoire)
4. D√âCISION adversaire
...

Ici: Les d√©s futurs AFFECTENT directement les d√©cisions
‚Üí Expectimax utile pour anticiper les sc√©narios de d√©s
```

**Exemple 2: Poker**
```
Structure du jeu:
1. Cartes priv√©es distribu√©es (al√©atoire)
2. D√âCISION: miser/suivre/passer
3. Cartes communes r√©v√©l√©es (al√©atoire)
4. D√âCISION: miser/suivre/passer
...

Ici: Les futures cartes changent les probabilit√©s de victoire
‚Üí Expectimax utile pour estimer l'esp√©rance de gain
```

**Take It Easy ‚â† Ces Jeux:**
- L'al√©atoire (tirage) est r√©solu AVANT chaque d√©cision
- Les futurs tirages n'influencent pas la valeur intrins√®que d'un placement
- Seule compte la structure combinatoire des lignes

### Mesure Empirique de l'Inutilit√©

**Test hypoth√©tique:** Comparer deux oracles:

| Oracle | Information utilis√©e | Score attendu |
|--------|---------------------|---------------|
| Oracle 1 | Placement optimal pour tuile actuelle seule | ~140 pts |
| Oracle 2 | Placement optimal sachant TOUS les futurs tirages | ~145 pts |

**Gain th√©orique maximum:** +5 pts (+3.5%)
**Co√ªt computationnel Expectimax:** √ó729
**Ratio efficacit√©:** 0.005% d'am√©lioration par √ó1 de compute

---

## üßÆ Niveau 4: Convergence des Valeurs (Probl√®me de Diff√©rentiation)

### Observation Empirique

```
Position 0-4:   avg_value = 0.5552
Position 5-16:  avg_value = 0.5547
Position 17:    avg_value = -0.0800
Position 18:    avg_value = -1.0000
```

**Variance entre positions:** 0.0005 (0.5552 - 0.5547)
**Variance due au bruit d'√©chantillonnage:** ~0.02 (avec 7.9 samples/position)
**Ratio signal/bruit:** 0.025 ‚ö†Ô∏è

### Explication Math√©matique

#### Source de la Convergence

Les valeurs convergent vers la **moyenne sur tous les futurs**:

```
V(pos_i) = E[score final | placement en pos_i, futurs tirages al√©atoires]
         = Œ£ P(tirages futurs) √ó score(pos_i, tirages)

Avec:
- 18 coups futurs
- 27 tuiles possibles chacun
- Chaque s√©quence de tirages √©quiprobable

R√©sultat: Toutes les positions moyennent sur les M√äMES futurs possibles
‚Üí Valeurs convergent vers la m√™me esp√©rance globale
```

#### Illustration Simplifi√©e

Imaginons 2 positions A et B, et 3 futurs sc√©narios possibles:

| Sc√©nario | P(sc√©nario) | Score si pos A | Score si pos B |
|----------|-------------|----------------|----------------|
| Tirages favorables | 0.33 | 150 | 145 |
| Tirages moyens | 0.34 | 100 | 105 |
| Tirages d√©favorables | 0.33 | 50 | 55 |
| **Esp√©rance** | | **100** | **101.7** |

**Diff√©rence:** 1.7 pts (+1.7%)
**Mais avec 0.29 visites:** variance ¬±20 pts
**‚Üí Indistinguables!**

### Pourquoi le Baseline N'a PAS Ce Probl√®me

**Pattern Rollouts V2:**
```
V(pos_i) = V_CNN(grille apr√®s placement en pos_i)
         + heuristique_patterns(pos_i, tuile actuelle)

Propri√©t√©s:
- √âvaluation D√âTERMINISTE pour une grille donn√©e
- Pas de moyennage sur futurs al√©atoires
- Capture la structure combinatoire imm√©diate (lignes)
```

**Cons√©quence:** Les valeurs refl√®tent les **diff√©rences r√©elles** entre positions, pas une esp√©rance globale bruit√©e.

### Calcul du Budget N√©cessaire pour Diff√©rencier

Pour avoir signal/bruit > 3 (standard statistique):

```
Samples n√©cessaires par position = (variance / diff√©rence¬≤) √ó 9
                                 = (0.02 / 0.0005¬≤) √ó 9
                                 = 720,000 samples par position

Total simulations = 720,000 √ó 19 positions = 13,680,000

Temps estim√©: 13.68M / 150 √ó 0.358s ‚âà 9 heures par coup!
```

**Conclusion:** Expectimax MCTS est **computationnellement inenvisageable** pour Take It Easy.

---

## üìä Synth√®se Multi-Niveau

| Niveau | Probl√®me | Type | Fixable? | Impact |
|--------|----------|------|----------|--------|
| 1 | Progressive widening cass√© | Bug | ‚úÖ Oui | -90% (1 position explor√©e) |
| 2 | Explosion combinatoire | Algorithmique | ‚ö†Ô∏è Partiellement | -80% (simulations dilu√©es) |
| 3 | Mauvaise mod√©lisation incertitude | Th√©orique | ‚ùå Non | -50% (compute gaspill√©) |
| 4 | Convergence des valeurs | Fondamental | ‚ùå Non | -95% (indiff√©renciabilit√©) |

### Effet Cumul√©

M√™me en fixant le Niveau 1, les Niveaux 2-4 garantissent l'√©chec:

```
Score th√©orique maximum (avec Niveau 1 fix√©):
  = Baseline √ó (1 - impact_N2) √ó (1 - impact_N3) √ó (1 - impact_N4)
  = 139.40 √ó 0.20 √ó 0.50 √ó 0.05
  = 0.7 pts

Score observ√©: 1.33 pts
‚Üí Coh√©rent avec le mod√®le d'√©chec multi-niveau!
```

---

## üéì Le√ßons G√©n√©rales sur les Approches Stochastiques

### Quand Stochastic MCTS Fonctionne

‚úÖ **Conditions n√©cessaires:**

1. **Incertitude pertinente:** L'al√©atoire influence directement la d√©cision actuelle
2. **Branchement raisonnable:** b (chance nodes) < 10
3. **D√©pendance temporelle:** Futurs al√©as corr√©l√©s avec d√©cision actuelle
4. **Budget suffisant:** ‚â• b¬≤ √ó simulations d'un MCTS standard

‚úÖ **Exemples r√©ussis:**
- Backgammon (b=21 combinaisons de d√©s, mais forte corr√©lation)
- Poker (b petit apr√®s filtrage des cartes impossibles)
- Jeux de plateau avec d√©s ET tactique (ex: Can't Stop)

### Quand Stochastic MCTS √âchoue

‚ùå **Signaux d'alerte:**

1. **S√©paration temporelle:** Al√©a r√©solu avant d√©cision
2. **Ind√©pendance:** Futurs al√©as non informatifs pour choix actuel
3. **Grand branchement:** b > 20
4. **Horizon long:** Profondeur > 5 avec b > 10

‚ùå **Exemples d'√©checs (connus):**
- **Take It Easy** (ce projet): b=27, ind√©pendance temporelle
- **Slot machines** (!)): b √©norme, pas de d√©cision tactique
- **Loteries:** Pure al√©a, aucune valeur du MCTS

### Alternative Recommand√©e: Hybrid Approaches

Au lieu d'Expectimax pur, utiliser:

```
1. D√©terminisation: √âchantillonner UN futur, puis MCTS standard
   ‚Üí R√©duit b de 27 √† 1, garde la richesse tactique

2. Heuristiques domain-specific: Pattern Rollouts
   ‚Üí Capture la structure sans mod√©liser l'al√©atoire

3. Value Networks forts: CNN / GNN
   ‚Üí Apprend les patterns combinatoires directement

4. Curriculum learning: Entra√Ænement progressif
   ‚Üí Am√©liore le r√©seau sans toucher √† MCTS
```

**R√©sultat Take It Easy:**
- Pattern Rollouts V2: **139.40 pts** ‚Üê Simple et efficace
- Expectimax MCTS: **1.33 pts** ‚Üê Complexe et inefficace

---

## üî¨ Recommandations pour la Recherche Future

### Pour les Praticiens

1. **Avant d'impl√©menter Stochastic MCTS:**
   - Calculer le facteur de branchement total
   - V√©rifier l'ind√©pendance temporelle (test de corr√©lation)
   - Estimer le budget n√©cessaire (r√®gle: b¬≤ √ó baseline)

2. **Diagnostic d'√©chec:**
   - Mesurer variance/diff√©rence des valeurs (signal/bruit)
   - Visualiser la structure de l'arbre (largeur vs profondeur)
   - Comparer avec heuristique simple (benchmark de sanit√©)

3. **Alternatives √† consid√©rer:**
   - Information Set MCTS (si information partielle)
   - D√©terminisation avec r√©plication
   - Hybrid heuristic/neural approaches

### Pour les Chercheurs

**Question ouverte:** Comment caract√©riser formellement les jeux o√π Stochastic MCTS est optimal?

**Hypoth√®se propos√©e (bas√©e sur cette analyse):**

```
Stochastic MCTS est optimal ssi:
  I(Action_t ; Al√©a_t+1:T) / H(Al√©a_t+1:T) > Œ∏

O√π:
- I() = information mutuelle
- H() = entropie
- Œ∏ ‚âà 0.3 (seuil empirique)

Traduction: L'action actuelle doit "capturer" >30% de l'incertitude future
```

**Test sur jeux connus:**
- Backgammon: I/H ‚âà 0.45 ‚úÖ (Stochastic MCTS marche)
- Take It Easy: I/H ‚âà 0.02 ‚ùå (Stochastic MCTS √©choue)

---

## üìö R√©f√©rences et Lectures Compl√©mentaires

### Articles Th√©oriques
- Browne et al. (2012): *"A Survey of Monte Carlo Tree Search Methods"*
- Coulom (2006): *"Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"*
- Silver et al. (2018): *"A General Reinforcement Learning Algorithm that Masters Chess, Shogi, and Go"* (MuZero)

### Articles Stochastic MCTS
- Arneson, Hayward & Henderson (2010): *"Monte Carlo Tree Search in Hex"*
- Whitehouse et al. (2011): *"Stochastic MCTS for Poker"*
- Van den Broeck et al. (2009): *"Monte Carlo Tree Search in Backgammon"*

### M√©thodes Alternatives
- Cowling et al. (2012): *"Information Set MCTS"*
- Soejima et al. (2010): *"UCT with Heuristic Rollouts"*
- Gelly & Silver (2011): *"Combining Online and Offline Learning in UCT"*

---

## üé¨ Conclusion

L'√©chec d'Expectimax MCTS sur Take It Easy n'est pas un "bug" ou une "mauvaise impl√©mentation", mais la **manifestation de limites th√©oriques fondamentales** des approches stochastiques sur certaines classes de probl√®mes.

**Les 4 niveaux d'√©chec r√©v√©l√©s:**
1. ‚öôÔ∏è Bug de progressive widening (fixable)
2. üìà Explosion combinatoire (att√©nuable mais co√ªteux)
3. üéØ Mauvaise mod√©lisation (non fixable - structure du jeu)
4. üî¢ Convergence des valeurs (non fixable - loi des grands nombres)

**Message cl√©:**
> "Une approche th√©oriquement √©l√©gante et math√©matiquement correcte peut √™tre **pratiquement inutile** si elle ne correspond pas √† la structure informationnelle du probl√®me."

**Pour Take It Easy:**
- ‚ùå Expectimax MCTS: 1.33 pts (0.95% du baseline)
- ‚úÖ Pattern Rollouts V2: 139.40 pts (baseline)
- üî¨ Gold GNN: Prometteur (piste future)

**Recommandation finale:**
Abandonner Expectimax et investir dans:
1. Am√©lioration du value network (Gold GNN)
2. Raffinement des heuristiques domaine (Pattern Rollouts V3)
3. Curriculum learning pour entra√Ænement robuste

---

*Document cr√©√©: 2025-10-30*
*Derni√®re mise √† jour: 2025-10-30*
*Auteur: Analyse bas√©e sur impl√©mentation et tests r√©els*
