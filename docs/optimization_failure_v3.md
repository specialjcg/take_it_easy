# Pattern Rollouts V3 - Analyse d'√âchec

## ‚ùå R√©sultats Catastrophiques

| Version | Score Moyen | vs V2 | Diagnostic |
|---------|-------------|-------|------------|
| **Pattern Rollouts V2** | **139.40 pts** | ‚Äî | ‚úÖ **Baseline stable** |
| **Pattern Rollouts V3** | **88.12 pts** | **-51.28 pts (-37%)** | ‚ùå **√âchec critique** |

**Configuration benchmark**: 50 parties, 150 simulations/coup, seed=2025

---

## üîß Optimisations Tent√©es (Toutes √âchou√©es)

### 1. Progressive Widening Trop Restrictif

**Changement**:
```rust
// V2 (baseline)
let top_k = ((total_visits as f64).sqrt() as usize).max(5);
// ‚Üí ‚àö150 = 12.2 coups explor√©s

// V3 (√©chec)
let top_k = ((total_visits as f64).cbrt() as usize + 3).max(4);
// ‚Üí ‚àõ150 + 3 = 8.3 coups explor√©s (-33%)
```

**Analyse de l'√©chec**:
- ‚ùå R√©duction de 12 ‚Üí 8 coups **trop agressive**
- ‚ùå R√©seau neural a besoin d'explorer suffisamment pour identifier les meilleurs coups
- ‚ùå Racine cubique cro√Æt trop lentement, bloquant la d√©couverte de bonnes positions

**Impact**: -20 √† -30 pts estim√©

---

### 2. c_puct Trop √âlev√© (Sur-exploration)

**Changement**:
```rust
// V2 (baseline)
let base_c_puct = match current_turn {
    0..=4   => 4.2,
    5..=15  => 3.8,
    16..=19 => 3.0,
};

// V3 (√©chec)
let base_c_puct = match current_turn {
    0..=4   => 4.5,  // +7%
    5..=15  => 4.0,  // +5%
    16..=19 => 3.2,  // +7%
};
```

**Analyse de l'√©chec**:
- ‚ùå Augmentation de 5-7% **trop importante**
- ‚ùå Encourage exploration au d√©triment de l'exploitation
- ‚ùå MCTS gaspille des simulations sur des coups sous-optimaux

**Impact**: -10 √† -15 pts estim√©

---

### 3. Coefficients D√©s√©quilibr√©s

**Changement**:
```rust
// V2 (baseline)
let combined_eval = 0.6 * normalized_value     // ValueNet
                  + 0.2 * normalized_rollout   // Rollouts
                  + 0.1 * normalized_heuristic // G√©om√©trie
                  + 0.1 * contextual;          // Contexte

// V3 (√©chec)
let combined_eval = 0.65 * normalized_value    // +8%
                  + 0.20 * normalized_rollout  // =
                  + 0.08 * normalized_heuristic // -20%
                  + 0.07 * contextual;         // -30%
```

**Analyse de l'√©chec**:
- ‚ùå Trop de confiance au ValueNet (0.65)
- ‚ùå R√©duction excessive des heuristiques g√©om√©triques (-20%)
- ‚ùå R√©duction excessive du contexte plateau (-30%)
- ‚ùå **Heuristiques encodent la connaissance du jeu**, r√©duire leur poids casse la synergie

**Impact**: -10 √† -20 pts estim√©

---

## üìä Cumul des Erreurs

| Optimisation | Impact estim√© | Cumul |
|--------------|---------------|-------|
| Progressive Widening restrictif | -20 √† -30 pts | -25 pts |
| c_puct trop √©lev√© | -10 √† -15 pts | -37.5 pts |
| Coefficients d√©s√©quilibr√©s | -10 √† -20 pts | -52.5 pts |

**Total impact**: **-52.5 pts** (proche du -51.28 pts observ√©)

---

## üí° Le√ßons Apprises

### 1. **Ne pas casser l'√©quilibre**

Pattern Rollouts V2 a atteint un √©quilibre fragile entre:
- Exploration (c_puct, Progressive Widening) ‚Üî Exploitation (meilleures positions)
- ValueNet (pr√©cision NN) ‚Üî Heuristiques (connaissance du domaine)
- Diversit√© (top_k √©lev√©) ‚Üî Focalisation (top_k bas)

**Modifier un seul param√®tre peut casser cet √©quilibre.**

### 2. **Progressive Widening: sqrt est optimal**

Pour 150 simulations:
- `sqrt(150) = 12` coups ‚Üí ‚úÖ **√âquilibre parfait**
- `cbrt(150) = 5` coups ‚Üí ‚ùå **Trop restrictif**
- `150^0.4 = 9` coups ‚Üí Peut-√™tre un compromis (non test√©)

**Conclusion**: Racine carr√©e est le bon compromis pour ce probl√®me.

### 3. **c_puct: √âviter la sur-exploration**

Les valeurs V2 (3.0-4.2) sont d√©j√† bien calibr√©es:
- Augmenter ‚Üí Trop d'exploration, gaspillage
- Diminuer ‚Üí Convergence pr√©matur√©e

**Conclusion**: Ne pas toucher sans raison forte.

### 4. **Heuristiques sont critiques**

R√©duire le poids des heuristiques (0.10 ‚Üí 0.08) et du contexte (0.10 ‚Üí 0.07) a √©t√© **d√©sastreux**.

**Pourquoi ?**
- Heuristiques encodent les **r√®gles du jeu** (compl√©tion de lignes, conflits)
- ValueNet apprend des **patterns statistiques** mais peut manquer des r√®gles
- **La synergie** entre NN et heuristiques est cl√©

**Conclusion**: [0.6, 0.2, 0.1, 0.1] est optimal, ne pas modifier.

---

## üéØ Recommandations

### Pour atteindre 145+ pts (5.60 pts manquants)

**Option A: Am√©liorer le r√©seau neural** ‚≠ê **Recommand√©**
- Gold GNN architecture (Graph Attention Networks)
- Meilleure capture des d√©pendances spatiales hexagonales
- Gain estim√©: +3-6 pts

**Option B: Tuning micro-ajustements**
- Variations infimes de c_puct (¬±0.1 max)
- Variations infimes de coefficients (¬±0.01 max)
- Gain estim√©: +1-2 pts (risque √©lev√©)

**Option C: Ne rien faire** ‚úÖ **Solution conservatrice**
- Pattern Rollouts V2 d√©passe d√©j√† les objectifs conservateur (136) et r√©aliste (138)
- Risque de r√©gression √©lev√©
- **"Perfect is the enemy of good"**

---

## üìù Conclusion

**Pattern Rollouts V2 est la solution finale optimale.**

Tentatives d'optimisation V3:
- ‚ùå Progressive Widening: √âchec
- ‚ùå c_puct augment√©: √âchec
- ‚ùå Coefficients ajust√©s: √âchec
- ‚ùå **R√©sultat global: -51.28 pts (-37%)**

**Les param√®tres V2 sont d√©j√† un optimum local robuste.**

Toute am√©lioration suppl√©mentaire n√©cessite:
1. Am√©lioration architecturale (Gold GNN)
2. R√©entra√Ænement du r√©seau neural
3. **Pas** de tuning des hyperparam√®tres MCTS existants

---

*Benchmark V3 r√©alis√© le 2025-10-25*
*Reverted to V2 imm√©diatement apr√®s diagnostic*
