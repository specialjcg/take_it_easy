# Guide d'entraÃ®nement du Transformer - Take It Easy

## ğŸ“Š DonnÃ©es disponibles

Vous avez **608 exemples d'entraÃ®nement** prÃªts Ã  utiliser :

### Fichiers de donnÃ©es:
- `game_data_states_transformer.pt`: Ã‰tats de jeu (608 Ã— 1 Ã— 5 Ã— 47 Ã— 1) - 560 KB
- `game_data_policy_raw_transformer.pt`: Politiques MCTS brutes (608 Ã— 19) - 47 KB
- `game_data_policy_boosted_transformer.pt`: Politiques MCTS boostÃ©es (608 Ã— 19) - 47 KB
- `game_data_boosts_transformer.pt`: IntensitÃ©s de boost (608 Ã— 1) - 4.6 KB
- `game_data_positions_transformer.pt`: Positions jouÃ©es (608 Ã— 1) - 6.8 KB
- `game_data_subscores_transformer.pt`: Sous-scores (608 Ã— 1) - 4.7 KB

### Historique:
- **632 parties** enregistrÃ©es dans `results.csv` (scores: 126-148)
- **100 epochs** d'entraÃ®nement dÃ©jÃ  effectuÃ©s (voir `transformer_training_history.csv`)
- Score Transformer actuel: ~11.35 (vs baseline MCTS: 142.85)

## ğŸš€ Commandes pour entraÃ®ner

### 1. VÃ©rifier les donnÃ©es
```bash
cargo run --release --bin inspect_pt
```

### 2. EntraÃ®ner le Transformer (si le trainer existe)
```bash
# Option A: Via le binaire principal
cargo run --release --bin take_it_easy -- --mode train-transformer --epochs 100

# Option B: Via un example dÃ©diÃ© (si crÃ©Ã©)
cargo run --release --example train_transformer

# Option C: Continuer l'entraÃ®nement existant
cargo run --release --bin take_it_easy -- --mode train-transformer --epochs 50 --resume
```

### 3. GÃ©nÃ©rer plus de donnÃ©es (optionnel)
```bash
# GÃ©nÃ©rer 200 parties supplÃ©mentaires
cargo run --release --bin take_it_easy -- --mode autotest --num-games 200 --num-simulations 150

# Monitoring en temps rÃ©el
tail -f training.log
```

### 4. Valider les performances

#### Test rapide (5 parties, ~5 min)
```bash
cargo test test_quick_validation \
  --test transformer_validation_quick_test \
  --release -- --ignored --nocapture
```

#### Test complet (20 parties, ~30 min)
```bash
cargo test test_transformer_vs_baseline_validation \
  --test transformer_validation_test \
  --release -- --ignored --nocapture
```

## ğŸ“ˆ Objectifs

**Baseline actuelle**: ~143 points (avec boosts MCTS)
**Transformer non-entraÃ®nÃ©**: ~11 points
**Objectif**: >140 points avec le Transformer

## ğŸ¯ Ã‰tapes recommandÃ©es

1. **VÃ©rifier que l'entraÃ®nement fonctionne** (prioritÃ© haute)
2. **EntraÃ®ner 100-200 epochs supplÃ©mentaires**
3. **Valider avec le test rapide**
4. **Si bon: gÃ©nÃ©rer plus de donnÃ©es et rÃ©-entraÃ®ner**
5. **Validation finale avec le test complet**

## ğŸ“ Notes

- Les donnÃ©es sont au format PyTorch (`.pt`)
- Le Transformer a 3 tÃªtes: policy, value, boost
- L'hybride combine Transformer + MCTS avec Î±=0.5
- Le boost prÃ©dit quelles positions sont boostÃ©es par les heuristiques

